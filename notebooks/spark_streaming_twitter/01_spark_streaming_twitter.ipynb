{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "01_spark_streaming_twitter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ralsouza/apache_spark_real_time_analytics/blob/master/notebooks/spark_streaming_twitter/01_spark_streaming_twitter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FStlW9EZG_M"
      },
      "source": [
        "!apt-get update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLCZHJ12ZHsm"
      },
      "source": [
        "# Install the dependencies\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7dtkfjwZH18"
      },
      "source": [
        "# Environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG5ynGHOZH5g"
      },
      "source": [
        "# tornar o pyspark \"importável\"\n",
        "import findspark\n",
        "findspark.init('spark-2.4.4-bin-hadoop2.7')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4Iw-FNAZH8j"
      },
      "source": [
        "# Libraries and Context Setup\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext, SparkConf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RDcvjlKZH_Q"
      },
      "source": [
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "\n",
        "\n",
        "# Instance Spark Session\n",
        "spark = SparkSession.builder.master('local').appName('My-SparkSQL').getOrCreate()\n",
        "\n",
        "# Create the SQL Context\n",
        "sqlContext = pyspark.SQLContext(sc)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swlHq0Bs0xrJ"
      },
      "source": [
        "Acesse http://localhost:4040 sempre que quiser acompanhar a execução dos jobs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I77PZZSV0xrK"
      },
      "source": [
        "## Spark Streaming - Twitter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWWShBwc0xrK",
        "outputId": "97ca79aa-fd4d-460e-f7d0-8749763701ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "# Pode ser necessário instalar esses pacotes\n",
        "!pip install requests_oauthlib\n",
        "!pip install twython\n",
        "!pip install nltk"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests_oauthlib in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests_oauthlib) (3.1.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests_oauthlib) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests_oauthlib) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests_oauthlib) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests_oauthlib) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests_oauthlib) (2.10)\n",
            "Collecting twython\n",
            "  Downloading https://files.pythonhosted.org/packages/24/80/579b96dfaa9b536efde883d4f0df7ea2598a6f3117a6dd572787f4a2bcfb/twython-3.8.2-py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from twython) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from twython) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->twython) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.4.0->twython) (3.1.0)\n",
            "Installing collected packages: twython\n",
            "Successfully installed twython-3.8.2\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjUKvd1Y0xrN"
      },
      "source": [
        "# Módulos usados\n",
        "from pyspark.streaming import StreamingContext\n",
        "from pyspark import SparkContext\n",
        "from requests_oauthlib import OAuth1Session\n",
        "from operator import add\n",
        "import requests_oauthlib\n",
        "from time import gmtime, strftime\n",
        "import requests\n",
        "import time\n",
        "import string\n",
        "import ast\n",
        "import json"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJOn0Bsm0xrP"
      },
      "source": [
        "# Pacote NLTK\n",
        "import nltk\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.sentiment import SentimentAnalyzer\n",
        "from nltk.corpus import subjectivity\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.sentiment.util import *"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBrAhd4S0xrR"
      },
      "source": [
        "# Frequência de update\n",
        "INTERVALO_BATCH = 5"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIXLsGLb0xrU"
      },
      "source": [
        "# Criando o StreamingContext\n",
        "ssc = StreamingContext(sc, INTERVALO_BATCH)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikioOogh0xrX"
      },
      "source": [
        "## Treinando o Classificador de Análise de Sentimento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAbARACp0xrX"
      },
      "source": [
        "Uma parte essencial da criação de um algoritmo de análise de sentimento (ou qualquer algoritmo de mineração de dados) é ter um conjunto de dados abrangente ou \"Corpus\" para o aprendizado, bem como um conjunto de dados de teste para garantir que a precisão do seu algoritmo atende aos padrões que você espera. Isso também permitirá que você ajuste o seu algoritmo a fim de deduzir melhores (ou mais precisas) características de linguagem natural que você poderia extrair do texto e que vão contribuir para a classificação de sentimento, em vez de usar uma abordagem genérica. Tomaremos como base o dataset de treino fornecido pela Universidade de Michigan, para competições do Kaggle --> https://inclass.kaggle.com/c/si650winter11."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCT4A9HU0xrY"
      },
      "source": [
        "Esse dataset contém 1,578,627 tweets classificados e cada linha é marcada como: \n",
        "\n",
        "### 1 para o sentimento positivo \n",
        "### 0 para o sentimento negativo "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orYfTsIx0xrY"
      },
      "source": [
        "# Lendo o arquivo texto e criando um RDD em memória com Spark\n",
        "arquivo = sc.textFile('/content/drive/My Drive/Colab Notebooks/08-apache-spark/data/dataset_analise_sentimento.csv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksqQFffB0xrb"
      },
      "source": [
        "# Removendo o cabeçalho\n",
        "header = arquivo.take(1)[0]\n",
        "dataset = arquivo.filter(lambda line: line != header)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEVU_OtF0xrd"
      },
      "source": [
        "type(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YWAdHE30xrf"
      },
      "source": [
        "# Essa função separa as colunas em cada linha, cria uma tupla e remove a pontuação.\n",
        "def get_row(line):\n",
        "  row = line.split(',')\n",
        "  sentimento = row[1]\n",
        "  tweet = row[3].strip()\n",
        "  translator = str.maketrans({key: None for key in string.punctuation})\n",
        "  tweet = tweet.translate(translator)\n",
        "  tweet = tweet.split(' ')\n",
        "  tweet_lower = []\n",
        "  for word in tweet:\n",
        "    tweet_lower.append(word.lower())\n",
        "  return (tweet_lower, sentimento)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_dmZK_E0xrh"
      },
      "source": [
        "# Aplica a função a cada linha do dataset\n",
        "dataset_treino = dataset.map(lambda line: get_row(line))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_-g8fhr0xrj"
      },
      "source": [
        "# Cria um objeto SentimentAnalyzer \n",
        "sentiment_analyzer = SentimentAnalyzer()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g78qKRIl0xrl",
        "outputId": "f6ccb501-6a16-474b-be6a-e061eddfd004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Certifique-se de ter espaço em disco - Aproximadamente 5GB\n",
        "# https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
        "# nltk.download()\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2HZDNF_0xro",
        "outputId": "37b4ee20-686f-4afe-8464-d5a69e15e87f",
        "colab": {
          "resources": {
            "http://localhost:8080/ntlkdata.png": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(url = 'ntlkdata.png')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"ntlkdata.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvV9agy20xrq"
      },
      "source": [
        "# Obtém a lista de stopwords em Inglês \n",
        "stopwords_all = []\n",
        "for word in stopwords.words('english'):\n",
        "  stopwords_all.append(word)\n",
        "  stopwords_all.append(word + '_NEG')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShpzqO3i0xrs"
      },
      "source": [
        "# Obtém 10.000 tweets do dataset de treino e retorna todas as palavras que não são stopwords\n",
        "dataset_treino_amostra = dataset_treino.take(10000)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MoTs0wv0xru"
      },
      "source": [
        "all_words_neg = sentiment_analyzer.all_words([mark_negation(doc) for doc in dataset_treino_amostra])\n",
        "all_words_neg_nostops = [x for x in all_words_neg if x not in stopwords_all]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDd-Dfw80xrw"
      },
      "source": [
        "# Cria um unigram (n-grama) e extrai as features\n",
        "unigram_feats = sentiment_analyzer.unigram_word_feats(all_words_neg_nostops, top_n = 200)\n",
        "sentiment_analyzer.add_feat_extractor(extract_unigram_feats, unigrams = unigram_feats)\n",
        "training_set = sentiment_analyzer.apply_features(dataset_treino_amostra)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1lVLc5z0xry",
        "outputId": "fc08b19c-2ff4-4bbd-99e7-a87c50b67278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(training_set)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nltk.collections.LazyMap"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFp788gL0xrz",
        "outputId": "0a29e10a-2121-427c-d27c-4e3ee5cbe7b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(training_set)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[({'contains()': False, 'contains(im)': False, 'contains(_NEG)': False, 'contains(followfriday)': False, 'contains(amp)': False, 'contains(dont)': False, 'contains(day)': False, 'contains(love)': False, 'contains(like)': False, 'contains(cant)': False, 'contains(good)': False, 'contains(get)': False, 'contains(go)': False, 'contains(today)': False, 'contains(got)': False, 'contains(want)': False, 'contains(time)': False, 'contains(going)': False, 'contains(back)': False, 'contains(one)': False, 'contains(sad)': True, 'contains(really)': False, 'contains(miss)': False, 'contains(u)': False, 'contains(work)': False, 'contains(new)': False, 'contains(2)': False, 'contains(last)': False, 'contains(still)': False, 'contains(twitter)': False, 'contains(night)': False, 'contains(great)': False, 'contains(lol)': False, 'contains(follow)': False, 'contains(need)': False, 'contains(see)': False, 'contains(much)': False, 'contains(myweakness)': False, 'contains(get_NEG)': False, 'contains(didnt)': False, 'contains(think)': False, 'contains(hate)': False, 'contains(iremember)': False, 'contains(home)': False, 'contains(feel)': False, 'contains(musicmonday)': False, 'contains(know)': False, 'contains(happy)': False, 'contains(people)': False, 'contains(lt3)': False, 'contains(would)': False, 'contains(bad)': False, 'contains(well)': False, 'contains(right)': False, 'contains(wish)': False, 'contains(oh)': False, 'contains(gonna)': False, 'contains(tomorrow)': False, 'contains(tonight)': False, 'contains(ff)': False, 'contains(ill)': False, 'contains(please)': False, 'contains(hope)': False, 'contains(thanks)': False, 'contains(morning)': False, 'contains(someone)': False, 'contains(never)': False, 'contains(ive)': False, 'contains(make)': False, 'contains(getting)': False, 'contains(im_NEG)': False, 'contains(go_NEG)': False, 'contains(know_NEG)': False, 'contains(awesome)': False, 'contains(like_NEG)': False, 'contains(inaperfectworld)': False, 'contains(thats)': False, 'contains(come)': False, 'contains(squarespace)': False, 'contains(wont)': False, 'contains(haha)': False, 'contains(lt)': False, 'contains(wanna)': False, 'contains(1)': False, 'contains(lost)': False, 'contains(days)': False, 'contains(4)': False, 'contains(makes)': False, 'contains(fun)': False, 'contains(friends)': False, 'contains(life)': False, 'contains(best)': False, 'contains(iphone)': False, 'contains(quoti)': False, 'contains(good_NEG)': False, 'contains(could)': False, 'contains(song)': False, 'contains(school)': False, 'contains(bed)': False, 'contains(better)': False, 'contains(dontyouhate)': False, 'contains(first)': False, 'contains(ever)': False, 'contains(3)': False, 'contains(us)': False, 'contains(haveyouever)': False, 'contains(sick)': False, 'contains(nice)': False, 'contains(man)': False, 'contains(want_NEG)': False, 'contains(doesnt)': False, 'contains(everyone)': False, 'contains(already)': False, 'contains(one_NEG)': False, 'contains(guys)': False, 'contains(show)': False, 'contains(sorry)': False, 'contains(week)': False, 'contains(music)': False, 'contains(things)': False, 'contains(old)': False, 'contains(bgt)': False, 'contains(next)': False, 'contains(made)': False, 'contains(something)': False, 'contains(n)': False, 'contains(way)': False, 'contains(another)': False, 'contains(gt)': False, 'contains(sleep)': False, 'contains(take)': False, 'contains(soon)': False, 'contains(baby)': False, 'contains(isnt)': False, 'contains(work_NEG)': False, 'contains(little)': False, 'contains(away)': False, 'contains(damn)': False, 'contains(quot)': False, 'contains(say)': False, 'contains(always)': False, 'contains(phone)': False, 'contains(left)': False, 'contains(shes)': False, 'contains(see_NEG)': False, 'contains(summer)': False, 'contains(weekend)': False, 'contains(year)': False, 'contains(today_NEG)': False, 'contains(amazing)': False, 'contains(wait_NEG)': False, 'contains(ok)': False, 'contains(long)': False, 'contains(girl)': False, 'contains(world)': False, 'contains(watching)': False, 'contains(movie)': False, 'contains(goodsex)': False, 'contains(feeling)': False, 'contains(ur)': False, 'contains(watch)': False, 'contains(cool)': False, 'contains(found)': False, 'contains(friend)': True, 'contains(mom)': False, 'contains(hes)': False, 'contains(friday)': False, 'contains(done)': False, 'contains(hours)': False, 'contains(said)': False, 'contains(went)': False, 'contains(gone)': False, 'contains(tired)': False, 'contains(house)': False, 'contains(missed)': False, 'contains(give)': False, 'contains(rain)': False, 'contains(leave)': False, 'contains(thing)': False, 'contains(wanted)': False, 'contains(head)': False, 'contains(sucks)': False, 'contains(sleep_NEG)': False, 'contains(ready)': False, 'contains(thank)': False, 'contains(guess)': False, 'contains(nothing)': False, 'contains(talk)': False, 'contains(followers)': False, 'contains(keep)': False, 'contains(tweets)': False, 'contains(look)': False, 'contains(hurts)': False, 'contains(early)': False, 'contains(game)': False, 'contains(two)': False, 'contains(guy)': False, 'contains(cry)': False, 'contains(going_NEG)': False, 'contains(live)': False}, '0'), ({'contains()': False, 'contains(im)': False, 'contains(_NEG)': False, 'contains(followfriday)': False, 'contains(amp)': False, 'contains(dont)': False, 'contains(day)': False, 'contains(love)': False, 'contains(like)': False, 'contains(cant)': False, 'contains(good)': False, 'contains(get)': False, 'contains(go)': False, 'contains(today)': False, 'contains(got)': False, 'contains(want)': False, 'contains(time)': False, 'contains(going)': False, 'contains(back)': False, 'contains(one)': False, 'contains(sad)': False, 'contains(really)': False, 'contains(miss)': False, 'contains(u)': False, 'contains(work)': False, 'contains(new)': True, 'contains(2)': False, 'contains(last)': False, 'contains(still)': False, 'contains(twitter)': False, 'contains(night)': False, 'contains(great)': False, 'contains(lol)': False, 'contains(follow)': False, 'contains(need)': False, 'contains(see)': False, 'contains(much)': False, 'contains(myweakness)': False, 'contains(get_NEG)': False, 'contains(didnt)': False, 'contains(think)': False, 'contains(hate)': False, 'contains(iremember)': False, 'contains(home)': False, 'contains(feel)': False, 'contains(musicmonday)': False, 'contains(know)': False, 'contains(happy)': False, 'contains(people)': False, 'contains(lt3)': False, 'contains(would)': False, 'contains(bad)': False, 'contains(well)': False, 'contains(right)': False, 'contains(wish)': False, 'contains(oh)': False, 'contains(gonna)': False, 'contains(tomorrow)': False, 'contains(tonight)': False, 'contains(ff)': False, 'contains(ill)': False, 'contains(please)': False, 'contains(hope)': False, 'contains(thanks)': False, 'contains(morning)': False, 'contains(someone)': False, 'contains(never)': False, 'contains(ive)': False, 'contains(make)': False, 'contains(getting)': False, 'contains(im_NEG)': False, 'contains(go_NEG)': False, 'contains(know_NEG)': False, 'contains(awesome)': False, 'contains(like_NEG)': False, 'contains(inaperfectworld)': False, 'contains(thats)': False, 'contains(come)': False, 'contains(squarespace)': False, 'contains(wont)': False, 'contains(haha)': False, 'contains(lt)': False, 'contains(wanna)': False, 'contains(1)': False, 'contains(lost)': False, 'contains(days)': False, 'contains(4)': False, 'contains(makes)': False, 'contains(fun)': False, 'contains(friends)': False, 'contains(life)': False, 'contains(best)': False, 'contains(iphone)': False, 'contains(quoti)': False, 'contains(good_NEG)': False, 'contains(could)': False, 'contains(song)': False, 'contains(school)': False, 'contains(bed)': False, 'contains(better)': False, 'contains(dontyouhate)': False, 'contains(first)': False, 'contains(ever)': False, 'contains(3)': False, 'contains(us)': False, 'contains(haveyouever)': False, 'contains(sick)': False, 'contains(nice)': False, 'contains(man)': False, 'contains(want_NEG)': False, 'contains(doesnt)': False, 'contains(everyone)': False, 'contains(already)': False, 'contains(one_NEG)': False, 'contains(guys)': False, 'contains(show)': False, 'contains(sorry)': False, 'contains(week)': False, 'contains(music)': False, 'contains(things)': False, 'contains(old)': False, 'contains(bgt)': False, 'contains(next)': False, 'contains(made)': False, 'contains(something)': False, 'contains(n)': False, 'contains(way)': False, 'contains(another)': False, 'contains(gt)': False, 'contains(sleep)': False, 'contains(take)': False, 'contains(soon)': False, 'contains(baby)': False, 'contains(isnt)': False, 'contains(work_NEG)': False, 'contains(little)': False, 'contains(away)': False, 'contains(damn)': False, 'contains(quot)': False, 'contains(say)': False, 'contains(always)': False, 'contains(phone)': False, 'contains(left)': False, 'contains(shes)': False, 'contains(see_NEG)': False, 'contains(summer)': False, 'contains(weekend)': False, 'contains(year)': False, 'contains(today_NEG)': False, 'contains(amazing)': False, 'contains(wait_NEG)': False, 'contains(ok)': False, 'contains(long)': False, 'contains(girl)': False, 'contains(world)': False, 'contains(watching)': False, 'contains(movie)': False, 'contains(goodsex)': False, 'contains(feeling)': False, 'contains(ur)': False, 'contains(watch)': False, 'contains(cool)': False, 'contains(found)': False, 'contains(friend)': False, 'contains(mom)': False, 'contains(hes)': False, 'contains(friday)': False, 'contains(done)': False, 'contains(hours)': False, 'contains(said)': False, 'contains(went)': False, 'contains(gone)': False, 'contains(tired)': False, 'contains(house)': False, 'contains(missed)': True, 'contains(give)': False, 'contains(rain)': False, 'contains(leave)': False, 'contains(thing)': False, 'contains(wanted)': False, 'contains(head)': False, 'contains(sucks)': False, 'contains(sleep_NEG)': False, 'contains(ready)': False, 'contains(thank)': False, 'contains(guess)': False, 'contains(nothing)': False, 'contains(talk)': False, 'contains(followers)': False, 'contains(keep)': False, 'contains(tweets)': False, 'contains(look)': False, 'contains(hurts)': False, 'contains(early)': False, 'contains(game)': False, 'contains(two)': False, 'contains(guy)': False, 'contains(cry)': False, 'contains(going_NEG)': False, 'contains(live)': False}, '0'), ...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-AWkYN00xr1",
        "outputId": "87af9c09-f361-477a-9e1d-bf10ef26baab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Treinar o modelo\n",
        "trainer = NaiveBayesClassifier.train\n",
        "classifier = sentiment_analyzer.train(trainer, training_set)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training classifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K-9zexw0xr3"
      },
      "source": [
        "# Testa o classificador em algumas sentenças\n",
        "test_sentence1 = [(['this', 'program', 'is', 'bad'], '')]\n",
        "test_sentence2 = [(['tough', 'day', 'at', 'work', 'today'], '')]\n",
        "test_sentence3 = [(['good', 'wonderful', 'amazing', 'awesome'], '')]\n",
        "test_set = sentiment_analyzer.apply_features(test_sentence1)\n",
        "test_set2 = sentiment_analyzer.apply_features(test_sentence2)\n",
        "test_set3 = sentiment_analyzer.apply_features(test_sentence3)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7wBQYp60xr5"
      },
      "source": [
        "# Autenticação do Twitter \n",
        "consumer_key = \"xxx\"\n",
        "consumer_secret = \"xxx\"\n",
        "access_token = \"xxx\"\n",
        "access_token_secret = \"xxx\""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NsQ7CeQ0xr7"
      },
      "source": [
        "# Especifica a URL termo de busca\n",
        "search_term = 'Trump'\n",
        "sample_url = 'https://stream.twitter.com/1.1/statuses/sample.json'\n",
        "filter_url = 'https://stream.twitter.com/1.1/statuses/filter.json?track='+search_term"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zbXeB2f0xr8"
      },
      "source": [
        "# Criando o objeto de atutenticação para o Twitter\n",
        "auth = requests_oauthlib.OAuth1(consumer_key, consumer_secret, access_token, access_token_secret)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxOoOAlB0xr_"
      },
      "source": [
        "# Configurando o Stream\n",
        "rdd = ssc.sparkContext.parallelize([0])\n",
        "stream = ssc.queueStream([], default = rdd)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SneeH9hm0xsB"
      },
      "source": [
        "type(stream)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O160HnJM0xsD"
      },
      "source": [
        "# Total de tweets por update\n",
        "NUM_TWEETS = 500  "
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teLU4ONL0xsE"
      },
      "source": [
        "# Essa função conecta ao Twitter e retorna um número específico de Tweets (NUM_TWEETS)\n",
        "def tfunc(t, rdd):\n",
        "  return rdd.flatMap(lambda x: stream_twitter_data())\n",
        "\n",
        "def stream_twitter_data():\n",
        "  response = requests.get(filter_url, auth = auth, stream = True)\n",
        "  print(filter_url, response)\n",
        "  count = 0\n",
        "  for line in response.iter_lines():\n",
        "    try:\n",
        "      if count > NUM_TWEETS:\n",
        "        break\n",
        "      post = json.loads(line.decode('utf-8'))\n",
        "      contents = [post['text']]\n",
        "      count += 1\n",
        "      yield str(contents)\n",
        "    except:\n",
        "      result = False"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTowNaBb0xsG"
      },
      "source": [
        "stream = stream.transform(tfunc)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ko-BkRE0xsI"
      },
      "source": [
        "coord_stream = stream.map(lambda line: ast.literal_eval(line))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5F4Sv8Q0xsK"
      },
      "source": [
        "# Essa função classifica os tweets, aplicando as features do modelo criado anteriormente\n",
        "def classifica_tweet(tweet):\n",
        "  sentence = [(tweet, '')]\n",
        "  test_set = sentiment_analyzer.apply_features(sentence)\n",
        "  print(tweet, classifier.classify(test_set[0][0]))\n",
        "  return(tweet, classifier.classify(test_set[0][0]))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odPEP1PQ0xsL"
      },
      "source": [
        "# Essa função retorna o texto do Twitter\n",
        "def get_tweet_text(rdd):\n",
        "  for line in rdd:\n",
        "    tweet = line.strip()\n",
        "    translator = str.maketrans({key: None for key in string.punctuation})\n",
        "    tweet = tweet.translate(translator)\n",
        "    tweet = tweet.split(' ')\n",
        "    tweet_lower = []\n",
        "    for word in tweet:\n",
        "      tweet_lower.append(word.lower())\n",
        "    return(classifica_tweet(tweet_lower))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyV4hCSQ0xsN"
      },
      "source": [
        "# Cria uma lista vazia para os resultados\n",
        "resultados = []"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZPpnoFx0xsP"
      },
      "source": [
        "# Essa função salva o resultado dos batches de Tweets junto com o timestamp\n",
        "def output_rdd(rdd):\n",
        "  global resultados\n",
        "  pairs = rdd.map(lambda x: (get_tweet_text(x)[1],1))\n",
        "  counts = pairs.reduceByKey(add)\n",
        "  output = []\n",
        "  for count in counts.collect():\n",
        "    output.append(count)\n",
        "  result = [time.strftime(\"%I:%M:%S\"), output]\n",
        "  resultados.append(result)\n",
        "  print(result)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2CnnsXb0xsQ"
      },
      "source": [
        "# A função foreachRDD() aplica uma função a cada RDD to streaming de dados\n",
        "coord_stream.foreachRDD(lambda t, rdd: output_rdd(rdd))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDxuaKW-0xsS"
      },
      "source": [
        "# Start streaming\n",
        "ssc.start()\n",
        "# ssc.awaitTermination()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzzr2NMF0xsU",
        "outputId": "1658938b-585b-40b0-9a1e-40770eaee806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "cont = True\n",
        "while cont:\n",
        "  if len(resultados) > 5:\n",
        "    cont = False"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['02:48:31', []]\n",
            "['02:48:47', [('0', 398), ('1', 103)]]\n",
            "['02:48:59', [('0', 409), ('1', 92)]]\n",
            "['02:49:11', [('0', 404), ('1', 97)]]\n",
            "['02:49:23', [('1', 100), ('0', 401)]]\n",
            "['02:49:35', [('0', 406), ('1', 95)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8gRWp4p0xsV"
      },
      "source": [
        "# Grava os resultados\n",
        "rdd_save = '/content/drive/My Drive/Colab Notebooks/08-apache-spark/data/r'+time.strftime(\"%I%M%S\")\n",
        "resultados_rdd = sc.parallelize(resultados)\n",
        "resultados_rdd.saveAsTextFile(rdd_save)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_bga7iX0xsX",
        "outputId": "4cf2b31c-5e57-4804-95c5-64580bfb4254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Visualiza os resultados\n",
        "resultados_rdd.collect()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['02:48:31', []],\n",
              " ['02:48:47', [('0', 398), ('1', 103)]],\n",
              " ['02:48:59', [('0', 409), ('1', 92)]],\n",
              " ['02:49:11', [('0', 404), ('1', 97)]],\n",
              " ['02:49:23', [('1', 100), ('0', 401)]],\n",
              " ['02:49:35', [('0', 406), ('1', 95)]],\n",
              " ['02:49:46', [('0', 401), ('1', 100)]],\n",
              " ['02:49:57', [('0', 394), ('1', 107)]],\n",
              " ['02:50:08', [('1', 100), ('0', 401)]],\n",
              " ['02:50:19', [('0', 407), ('1', 94)]],\n",
              " ['02:50:30', [('0', 412), ('1', 89)]],\n",
              " ['02:50:41', [('0', 418), ('1', 83)]],\n",
              " ['02:50:52', [('0', 405), ('1', 96)]],\n",
              " ['02:51:03', [('0', 410), ('1', 91)]],\n",
              " ['02:51:14', [('1', 93), ('0', 408)]],\n",
              " ['02:51:25', [('0', 412), ('1', 89)]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeVJPp2U0xsZ"
      },
      "source": [
        "# Finaliza o streaming\n",
        "ssc.stop()"
      ],
      "execution_count": 49,
      "outputs": []
    }
  ]
}